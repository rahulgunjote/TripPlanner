default_platform(:ios)

platform :ios do
  # Variables
  SCHEME = "TripPlanner"
  PROJECT = "TripPlanner.xcodeproj"
  
  # Detect CI environment
  IS_CI = ENV['CI'] == 'true' || ENV['GITHUB_ACTIONS'] == 'true'
  
  # Configuration based on environment
  if IS_CI
    # CI Environment (GitHub Actions)
    SIMULATOR = "iPhone 16"
    IOS_VERSION = "18.5"  # Xcode 16.4 supports up to iOS 18.5.99
    XCODE_VERSION = "16.4"
  else
    # Local Development Environment
    SIMULATOR = "iPhone 17"
    IOS_VERSION = "26.0"
    XCODE_VERSION = nil # Skip Xcode version check locally
  end
  
  before_all do
    if IS_CI
      UI.important("ğŸ¤– Running in CI environment")
      UI.message("Simulator: #{SIMULATOR}")
      UI.message("iOS Version: #{IOS_VERSION}")
      ensure_xcode_version(version: XCODE_VERSION)
    else
      UI.important("ğŸ’» Running in local environment")
      UI.message("Simulator: #{SIMULATOR}")
      UI.message("iOS Version: #{IOS_VERSION}")
    end
  end

  desc "Build the project"
  lane :build do
    UI.message("ğŸ”¨ Building TripPlanner...")
    
    destination = "platform=iOS Simulator,name=#{SIMULATOR},OS=#{IOS_VERSION}"
    UI.message("Building for destination: #{destination}")
    
    xcodebuild(
      scheme: SCHEME,
      project: PROJECT,
      configuration: "Debug",
      destination: destination,
      clean: true,
      build: true,
      xcargs: "-quiet"
    )
    
    UI.success("âœ… Build completed successfully!")
  end

  desc "Run all tests"
  lane :test do
    UI.message("ğŸ§ª Running all tests...")
    
    destination = "platform=iOS Simulator,name=#{SIMULATOR},OS=#{IOS_VERSION}"
    UI.message("Testing on destination: #{destination}")
    
    scan(
      scheme: SCHEME,
      project: PROJECT,
      destination: destination,
      clean: true,
      code_coverage: true,
      only_testing: ["TripPlannerTests"],
      output_directory: "./fastlane/test_output",
      output_types: "html,junit",
      fail_build: true,
      reset_simulator: true
    )
    
    UI.success("âœ… All tests passed!")
  end

  desc "Run unit tests only"
  lane :unit_tests do
    UI.message("ğŸ§ª Running unit tests...")
    
    destination = "platform=iOS Simulator,name=#{SIMULATOR},OS=#{IOS_VERSION}"
    UI.message("Testing on destination: #{destination}")
    
    scan(
      scheme: SCHEME,
      project: PROJECT,
      destination: destination,
      clean: true,
      code_coverage: true,
      only_testing: ["TripPlannerTests"],
      output_directory: "./fastlane/test_output/unit_tests",
      output_types: "html,junit",
      fail_build: true,
      reset_simulator: true
    )
    
    UI.success("âœ… Unit tests passed!")
  end

  desc "Build for testing (used in CI)"
  lane :build_for_testing do
    UI.message("ğŸ”¨ Building for testing...")
    
    destination = "platform=iOS Simulator,name=#{SIMULATOR},OS=#{IOS_VERSION}"
    UI.message("Building for destination: #{destination}")
    
    xcodebuild(
      scheme: SCHEME,
      project: PROJECT,
      configuration: "Debug",
      destination: destination,
      build_for_testing: true,
      xcargs: "-quiet"
    )
    
    UI.success("âœ… Build for testing completed!")
  end

  desc "Generate code coverage report"
  lane :coverage do
    UI.message("ğŸ“Š Generating code coverage report...")
    
    xcov(
      scheme: SCHEME,
      project: PROJECT,
      output_directory: "./fastlane/test_output/coverage",
      minimum_coverage_percentage: 60.0,
      ignore_file_path: "./.xcovignore"
    )
    
    UI.success("âœ… Coverage report generated!")
  end

  desc "Lint Swift code"
  lane :lint do
    UI.message("ğŸ” Linting Swift code...")
    
    # Note: Requires SwiftLint to be installed
    # Install with: brew install swiftlint
    swiftlint(
      mode: :lint,
      config_file: ".swiftlint.yml",
      reporter: "html",
      output_file: "./fastlane/test_output/swiftlint.html",
      ignore_exit_status: false
    )
    
    UI.success("âœ… Linting completed!")
  end

  desc "Run full CI pipeline"
  lane :ci do
    UI.message("ğŸš€ Running full CI pipeline...")
    
    build
    unit_tests
    
    UI.success("âœ… CI pipeline completed successfully!")
  end
  
  # MARK: - Launchable Integration
  
  desc "Record build for Launchable"
  lane :launchable_record_build do
    UI.message("ğŸ“ Recording build with Launchable...")
    
    sh("launchable record build --name '#{ENV['GITHUB_RUN_ID'] || Time.now.to_i}'")
    
    UI.success("âœ… Build recorded!")
  end
  
  desc "Run full test suite and upload to Launchable (for training ML models)"
  lane :launchable_train do
    UI.header("ğŸ“Š Running Full Test Suite for Launchable Training")
    
    # Record session start
    session_id = sh("launchable record session --build '#{ENV['GITHUB_RUN_ID'] || Time.now.to_i}'", log: false).strip
    ENV['LAUNCHABLE_SESSION_ID'] = session_id
    UI.message("Session ID: #{session_id}")
    
    # Run full test suite
    UI.message("ğŸ§ª Running all tests...")
    begin
      test  # Run full suite
    rescue => e
      UI.error("âŒ Tests failed: #{e.message}")
      # Continue to upload results even if tests fail
    end
    
    # Record test results
    UI.message("ğŸ“¤ Uploading test results to Launchable for training...")
    
    # Debug: Show current directory and check what files exist
    UI.message("ğŸ” Current working directory: #{Dir.pwd}")
    
    # Try multiple path patterns
    search_patterns = [
      "./fastlane/test_output/**/*.junit",
      "fastlane/test_output/**/*.junit",
      "#{Dir.pwd}/fastlane/test_output/**/*.junit",
      "./test_output/**/*.junit"
    ]
    
    junit_files = []
    search_patterns.each do |pattern|
      files = Dir.glob(pattern)
      if !files.empty?
        UI.message("âœ… Found files with pattern: #{pattern}")
        junit_files = files
        break
      end
    end
    
    if junit_files.empty?
      UI.important("âš ï¸ No JUnit files found to upload")
      UI.message("Searched patterns:")
      search_patterns.each { |p| UI.message("  - #{p}") }
      
      # List what files DO exist in test_output
      if Dir.exist?("./fastlane/test_output")
        UI.message("Files in ./fastlane/test_output:")
        Dir.glob("./fastlane/test_output/**/*").each { |f| UI.message("  - #{f}") }
      elsif Dir.exist?("fastlane/test_output")
        UI.message("Files in fastlane/test_output:")
        Dir.glob("fastlane/test_output/**/*").each { |f| UI.message("  - #{f}") }
      else
        UI.message("âš ï¸ test_output directory doesn't exist")
      end
    else
      UI.message("ğŸ“ Found #{junit_files.count} JUnit file(s):")
      junit_files.each { |f| UI.message("   - #{f}") }
      
      begin
        # Upload each JUnit file to Launchable
        junit_files.each do |junit_file|
          sh("launchable record tests --session #{session_id} xctest '#{junit_file}'")
        end
        UI.success("âœ… Test results uploaded to Launchable")
        UI.message("ğŸ“ˆ This data will be used to train ML models for intelligent test selection")
      rescue => e
        UI.error("âŒ Failed to upload test results: #{e.message}")
        raise e  # Fail the build if upload fails
      end
    end
    
    UI.success("âœ… Training data uploaded successfully!")
  end
  
  desc "Run tests with Launchable intelligent subset (for PRs)"
  lane :launchable_subset_test do
    UI.header("ğŸ§  Running Launchable Intelligent Test Selection")
    
    # Record session start
    session_id = sh("launchable record session --build '#{ENV['GITHUB_RUN_ID'] || Time.now.to_i}'", log: false).strip
    ENV['LAUNCHABLE_SESSION_ID'] = session_id
    UI.message("Session ID: #{session_id}")
    
    # Build for testing
    UI.message("ğŸ”¨ Building for testing...")
    build_for_testing
    
    # Try to get intelligent subset from Launchable
    UI.message("ğŸ¯ Getting intelligent test subset from Launchable...")
    
    subset_tests = []
    use_launchable_subset = false
    
    begin
      # Step 1: Get list of all available tests from test files
      UI.message("ğŸ“‹ Discovering available tests from test files...")
      
      # Get project root directory (where .xcodeproj is)
      project_root = File.dirname(File.expand_path(PROJECT))
      UI.message("ğŸ” Project root: #{project_root}")
      UI.message("ğŸ” Current directory: #{Dir.pwd}")
      
      # Find all test files - check multiple possible paths
      # Fastlane usually runs from project root, but check multiple paths
      search_paths = [
        "./TripPlannerTests/**/*Tests.swift",  # From current directory
        "../TripPlannerTests/**/*Tests.swift",  # From fastlane subdirectory
        "#{project_root}/TripPlannerTests/**/*Tests.swift",  # From project root
        "#{Dir.pwd}/TripPlannerTests/**/*Tests.swift"  # Current absolute path
      ]
      
      test_files = []
      search_paths.each do |pattern|
        test_files = Dir.glob(pattern)
        if !test_files.empty?
          UI.message("âœ… Found test files using pattern: #{pattern}")
          break
        end
      end
      
      if test_files.empty?
        UI.error("âŒ No test files found!")
        UI.message("Searched patterns:")
        search_paths.each { |p| UI.message("  - #{p}") }
        raise "No test files discovered"
      end
      
      UI.message("ï¿½ Found #{test_files.count} test files")
      all_tests = []
      tests_by_file = {}
      
      # Parse test files to extract test methods
      test_files.each do |file|
        content = File.read(file)
        class_name = File.basename(file, ".swift")
        file_tests = Set.new  # Use Set to avoid duplicates
        
        # Detect framework being used
        uses_swift_testing = content.include?("import Testing")
        uses_xctest = content.include?("import XCTest")
        
        if uses_swift_testing
          # Swift Testing framework: Look for @Test annotations
          # Pattern: @Test("description") func testName() or @Test func testName()
          content.scan(/@Test(?:\([^)]*\))?\s+func\s+(\w+)\(\s*\)/).each do |match|
            test_method = match[0]
            test_id = "TripPlannerTests/#{class_name}/#{test_method}"
            all_tests << test_id unless all_tests.include?(test_id)
            file_tests.add(test_method)
          end
        end
        
        if uses_xctest
          # XCTest framework: Look for test methods in classes
          # Pattern: func testXXX() inside a class that inherits from XCTestCase
          # First check if this file has XCTestCase
          if content =~ /class\s+\w+\s*:\s*XCTestCase/
            content.scan(/func (test\w+)\(\s*\)/).each do |match|
              test_method = match[0]
              test_id = "TripPlannerTests/#{class_name}/#{test_method}"
              all_tests << test_id unless all_tests.include?(test_id)
              file_tests.add(test_method)
            end
          end
        end
        
        # If neither framework detected, try to find any test methods as fallback
        if !uses_swift_testing && !uses_xctest
          UI.important("âš ï¸ #{class_name}: No test framework detected, scanning for test methods...")
          content.scan(/func (test\w+)\(\s*\)/).each do |match|
            test_method = match[0]
            test_id = "TripPlannerTests/#{class_name}/#{test_method}"
            all_tests << test_id unless all_tests.include?(test_id)
            file_tests.add(test_method)
          end
        end
        
        framework_info = []
        framework_info << "Swift Testing" if uses_swift_testing
        framework_info << "XCTest" if uses_xctest
        framework_str = framework_info.empty? ? "Unknown" : framework_info.join(" + ")
        
        tests_by_file[class_name] = { count: file_tests.size, framework: framework_str }
      end
      
      if all_tests.empty?
        UI.error("âš ï¸ No test methods found in test files!")
        UI.message("Files checked: #{tests_by_file.keys.join(', ')}")
        raise "No tests discovered"
      end
      
      UI.message("ğŸ“Š Found #{all_tests.count} total tests across #{test_files.count} test files")
      tests_by_file.each do |file, info|
        UI.message("   #{file}: #{info[:count]} tests (#{info[:framework]})")
      end
      
      # Step 2: Write test list to file for Launchable
      test_list_file = "./launchable_test_list.txt"
      File.write(test_list_file, all_tests.join("\n"))
      UI.message("ğŸ“ Test list written to #{test_list_file}")
      
      # Step 3: Get subset recommendation from Launchable
      UI.message("ğŸ§  Requesting intelligent subset from Launchable ML...")
      subset_output_file = "./launchable_subset.txt"
      
      # Use launchable subset command (target 60% time reduction)
      # Note: 'launchable subset file' reads from stdin, not from a file argument
      subset_cmd = "cat #{test_list_file} | launchable subset --session #{session_id} --target 40% file > #{subset_output_file}"
      sh(subset_cmd)
      
      # Step 4: Parse Launchable's recommendations
      subset_content = File.read(subset_output_file).strip
      
      if subset_content.empty?
        UI.important("âš ï¸ Launchable returned empty subset, using default")
        raise "Empty subset"
      end
      
      # Extract test identifiers from subset
      subset_tests_raw = subset_content.split("\n").reject(&:empty?)
      
      # Group tests by class for scan's only_testing parameter
      # Convert "TripPlannerTests/ClassName/testMethod" to "TripPlannerTests/ClassName/testMethod"
      subset_tests = subset_tests_raw.map { |t| t.strip }
      
      if subset_tests.empty?
        UI.important("âš ï¸ No valid tests in subset, using default")
        raise "Empty subset after parsing"
      end
      
      UI.success("âœ… Launchable recommended #{subset_tests.count}/#{all_tests.count} tests (#{(subset_tests.count.to_f/all_tests.count*100).round}%)")
      UI.message("ğŸ¯ Selected tests:")
      subset_tests.first(10).each { |t| UI.message("   - #{t}") }
      UI.message("   ... and #{subset_tests.count - 10} more") if subset_tests.count > 10
      
      use_launchable_subset = true
      
    rescue => e
      UI.error("âŒ Failed to get Launchable subset: #{e.message}")
      UI.important("âš ï¸ Falling back to full test suite")
      subset_tests = nil
      use_launchable_subset = false
    end
    
    # Step 5: Run the subset tests
    begin
      destination = "platform=iOS Simulator,name=#{SIMULATOR},OS=#{IOS_VERSION}"
      
      if use_launchable_subset && !subset_tests.nil? && !subset_tests.empty?
        UI.important("ğŸ¯ Running Launchable-recommended test subset (#{subset_tests.count} tests)")
        
        scan(
          scheme: SCHEME,
          project: PROJECT,
          destination: destination,
          only_testing: subset_tests,
          code_coverage: true,
          output_directory: "./fastlane/test_output",
          output_types: "html,junit",
          fail_build: true,
          reset_simulator: true
        )
        
        UI.success("âœ… Intelligent subset tests completed successfully")
      else
        UI.important("ğŸ¯ Running full test suite (Launchable subset unavailable)")
        
        scan(
          scheme: SCHEME,
          project: PROJECT,
          destination: destination,
          clean: true,
          code_coverage: true,
          only_testing: ["TripPlannerTests"],
          output_directory: "./fastlane/test_output",
          output_types: "html,junit",
          fail_build: true,
          reset_simulator: true
        )
        
        UI.success("âœ… Full test suite completed successfully")
      end
      
    rescue => e
      UI.error("âŒ Test execution failed: #{e.message}")
      raise e
    end
    
    # Step 6: Upload test results to Launchable
    UI.message("ğŸ“¤ Uploading test results to Launchable...")
    
    # Find JUnit XML files
    junit_files = Dir.glob("./fastlane/test_output/**/*.junit")
    
    if junit_files.empty?
      UI.important("âš ï¸ No JUnit files found to upload")
      UI.message("Searched path: ./fastlane/test_output/**/*.junit")
    else
      UI.message("ğŸ“ Found #{junit_files.count} JUnit file(s):")
      junit_files.each { |f| UI.message("   - #{f}") }
      
      begin
        # Upload each JUnit file to Launchable
        junit_files.each do |junit_file|
          sh("launchable record tests --session #{session_id} xctest '#{junit_file}'")
        end
        UI.success("âœ… Test results uploaded to Launchable")
        
        if use_launchable_subset
          UI.message("ğŸ“ˆ Launchable ML model will learn from these results")
        end
      rescue => e
        UI.error("âŒ Failed to upload test results: #{e.message}")
        UI.important("Continuing anyway...")
      end
    end
    
    # Cleanup temporary files
    sh("rm -f ./launchable_test_list.txt ./launchable_subset.txt", log: false) rescue nil
    
    UI.success("âœ… Launchable subset testing completed!")
  end
  
  desc "Run tests with Launchable (with fallback)"
  lane :launchable_test do
    begin
      launchable_subset_test
    rescue => e
      UI.error("âŒ Launchable test failed: #{e.message}")
      UI.important("âš ï¸ Falling back to full test suite...")
      test
    end
  end
  
  desc "Verify Launchable setup"
  lane :launchable_verify do
    UI.header("ğŸ” Verifying Launchable Setup")
    
    # Check if launchable is installed
    begin
      version = sh("launchable --version", log: false).strip
      UI.success("âœ… Launchable installed: #{version}")
    rescue
      UI.error("âŒ Launchable not installed")
      UI.message("Install with: pip install launchable")
      next
    end
    
    # Check if token is set
    if ENV['LAUNCHABLE_TOKEN'].nil? || ENV['LAUNCHABLE_TOKEN'].empty?
      UI.error("âŒ LAUNCHABLE_TOKEN not set")
      UI.message("Set with: export LAUNCHABLE_TOKEN=your_token")
    else
      UI.success("âœ… LAUNCHABLE_TOKEN is set")
    end
    
    # Verify organization
    begin
      sh("launchable verify")
      UI.success("âœ… Launchable authentication successful")
    rescue
      UI.error("âŒ Launchable authentication failed")
    end
    
    UI.success("âœ… Launchable verification complete!")
  end

  desc "Clean build artifacts"
  lane :clean do
    UI.message("ğŸ§¹ Cleaning build artifacts...")
    
    clear_derived_data
    
    UI.success("âœ… Cleanup completed!")
  end

  # Error handling
  error do |lane, exception|
    UI.error("âŒ Lane #{lane} failed with error: #{exception.message}")
  end
end

